{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compensate and classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "lukeeno = \"/home/lukeeno/Gitais/bachelor_thesis\"\n",
    "carishkaa = \"/Users/karinabalagazova/Desktop/cvut/5.semestr/scientificProject/notebooks/..\"\n",
    "sys.path.append(lukeeno)\n",
    "import os.path\n",
    "# from functions.experiment import experiment_iteration\n",
    "from functions.rnaseq_data_generator import rna_seq_generator, NormalDistributionParameters\n",
    "from utils.enums import Distribution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "\n",
    "from functions.saving_data import get_empty_auc_dataset\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prepare to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_distribution = 'neg-binomial' # 'poisson' or 'neg-binomial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create folder to save generated data\n",
    "# from pathlib import Path\n",
    "# import datetime\n",
    "# foldername_generated_data = 'generated-data-' + data_distribution + '-' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "# Path(foldername_generated_data).mkdir(parents=True, exist_ok=True)\n",
    "# print('All datasets will be stored in \\\"' + foldername_generated_data + '\\\" folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: File with this name already exists!\n"
     ]
    }
   ],
   "source": [
    "# Get and save EMPTY dict for storing classification results\n",
    "data = get_empty_auc_dataset()\n",
    "filename_auc_results_origin = 'newauc_results_origin_'+ data_distribution + '.npz'\n",
    "filename_auc_results_expected = 'newauc_results_expected_'+ data_distribution + '.npz'\n",
    "filename_auc_results_filtered = 'newauc_results_filtered_'+ data_distribution + '.npz'\n",
    "\n",
    "if os.path.isfile(filename_auc_results_origin) or \\\n",
    "        os.path.isfile(filename_auc_results_expected) or \\\n",
    "        os.path.isfile(filename_auc_results_filtered):\n",
    "    print('WARNING: File with this name already exists!')\n",
    "else:\n",
    "    np.savez(filename_auc_results_origin, auc_data=data)\n",
    "    np.savez(filename_auc_results_expected, auc_data=data)\n",
    "    np.savez(filename_auc_results_filtered, auc_data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Arrays for storing classification results\n",
    "saved_origin = np.load(filename_auc_results_origin, allow_pickle=True)\n",
    "saved_origin = saved_origin['auc_data'].item()\n",
    "\n",
    "saved_expected = np.load(filename_auc_results_expected, allow_pickle=True)\n",
    "saved_expected = saved_expected['auc_data'].item()\n",
    "\n",
    "saved_filtered = np.load(filename_auc_results_filtered, allow_pickle=True)\n",
    "saved_filtered = saved_filtered['auc_data'].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def learn_beta_poisson(df):\n",
    "    mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.Poisson(), data=df).fit()\n",
    "    return np.array([mp.params.x1, mp.params.x2, mp.params.x3])\n",
    "    \n",
    "def learn_beta_neg_binomial(df):\n",
    "    mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.NegativeBinomial(), data=df).fit()\n",
    "    return np.array([mp.params.x1, mp.params.x2, mp.params.x3])\n",
    "\n",
    "def compensation(counts, IS, t, n_CR, distribution, pool: Pool):\n",
    "    \"\"\"\n",
    "    IS compensation.\n",
    "\n",
    "    :param counts: Counts to be compensated.\n",
    "    :param IS: Array of immunosuppression intake (0 or 1).\n",
    "    :param t: Number of transcripts.\n",
    "    :param distribution: \"Poisson\" or \"Negative binomial\".\n",
    "    :param n_CR: Number of samples in CR class. First n_CR elements of counts must be of CR class.\n",
    "    \"\"\"\n",
    "    # leave only STA\n",
    "    STA_patients = counts.columns.str.startswith('STA')\n",
    "    STA_counts = counts.loc[:, STA_patients].to_numpy()\n",
    "    STA_IS = IS.loc[STA_patients]\n",
    "\n",
    "    # try to learn the beta1 parameters from STA class\n",
    "    learned_beta = np.zeros((3, t))\n",
    "    values = list()\n",
    "    for ind in range(t):\n",
    "        values.append(pd.DataFrame({\"x1\": STA_IS['IS1'].values.tolist(),\n",
    "                           \"x2\": STA_IS['IS2'].values.tolist(),\n",
    "                           \"x3\": STA_IS['IS3'].values.tolist(),\n",
    "                           \"y\": STA_counts[ind]}))\n",
    "\n",
    "    vs = pool.map(learn_beta_poisson, values) if distribution == \"Poisson\" else \\\n",
    "    pool.map(learn_beta_neg_binomial, values) if distribution == \"Negative binomial\" else \\\n",
    "        False\n",
    "\n",
    "    if not vs:\n",
    "        print('Something is bad with pool.map(...)')\n",
    "\n",
    "    for ind in range(t):\n",
    "        learned_beta[:, ind] = vs[ind]\n",
    "    \n",
    "    # leave only CR and OT classes for classification\n",
    "    OT_CR_counts = counts.loc[:, ~STA_patients].to_numpy(dtype=float)\n",
    "    OT_CR_IS = IS.loc[~STA_patients].values\n",
    "\n",
    "    # filter out IS from CR\n",
    "    OT_CR_counts[:, :n_CR] = OT_CR_counts[:, :n_CR] / np.exp(np.dot(OT_CR_IS[:n_CR], learned_beta).transpose())\n",
    "    OT_CR_counts = OT_CR_counts.transpose()\n",
    "    return OT_CR_counts, OT_CR_IS, learned_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(generated_counts, generated_expected_counts, generated_IS, n_CR: int, distribution, pool):\n",
    "    # counts generated with IS influence\n",
    "    counts, patients_labels, _ = preprocess_for_classification(generated_counts)\n",
    "\n",
    "    # counts generated with similar beta0, but without IS influence\n",
    "    expected_counts, _, _ = preprocess_for_classification(generated_expected_counts)\n",
    "\n",
    "    # IS compensation\n",
    "    t = generated_counts.shape[0]\n",
    "    filtered_counts, OT_CR_IS, learned_beta = compensation(generated_counts, generated_IS, t, n_CR, distribution, pool)\n",
    "\n",
    "    columns = [\"transcript\" + str(num) for num in range(counts.shape[1])]\n",
    "    y = pd.DataFrame(data=patients_labels)\n",
    "\n",
    "    datasets_to_save = dict()\n",
    "    datasets_to_save['learned_beta'] = learned_beta\n",
    "    datasets_to_save['y'] = y\n",
    "\n",
    "    # COUNTS\n",
    "    X = pd.DataFrame(data=counts, columns=columns)\n",
    "    results_origin = classify(X, y.values.ravel(), n_splits=10, n_repeats=1)\n",
    "    datasets_to_save['origin_X'] = X\n",
    "\n",
    "    # EXPECTED\n",
    "    X = pd.DataFrame(data=expected_counts, columns=columns)\n",
    "    results_expected = classify(X, y.values.ravel(), n_splits=10, n_repeats=1)\n",
    "    datasets_to_save['expected_X'] = X\n",
    "\n",
    "    # FILTERED\n",
    "    X = pd.DataFrame(data=filtered_counts, columns=columns)\n",
    "    results_filtered = classify(X, y.values.ravel(), n_splits=10, n_repeats=1)\n",
    "    datasets_to_save['filtered_X'] = X\n",
    "\n",
    "    return results_origin, results_expected, results_filtered, datasets_to_save\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from functions.classificator import classify\n",
    "from functions.data_preprocess import preprocess_for_classification\n",
    "\n",
    "def experiment_iteration(STA_range, n_repeats, gen_origin, gen_expected, gen_IS,\n",
    "                         n_genSTA, n_genCR, n_genOT,\n",
    "                         distribution, pool, filename):\n",
    "    n_STA = STA_range[-1]  # maximal number of STA patients\n",
    "\n",
    "    # arrays for AUC results\n",
    "    mean_auc_results_origin = np.zeros((n_repeats, len(STA_range)))\n",
    "    mean_auc_results_expected = np.zeros((n_repeats, len(STA_range)))\n",
    "    mean_auc_results_filtered = np.zeros((n_repeats, len(STA_range)))\n",
    "\n",
    "    for j in range(n_repeats):\n",
    "        STA_random_index = random.sample(range(n_genSTA), n_STA)\n",
    "        CR_random_index = random.sample(range(n_genCR), 15)\n",
    "        OT_random_index = random.sample(range(n_genOT), 15)\n",
    "\n",
    "        counts_STA = gen_origin[0][gen_origin[0].columns[STA_random_index]]\n",
    "        counts_CR = gen_origin[1][gen_origin[1].columns[CR_random_index]]\n",
    "        counts_OT = gen_origin[2][gen_origin[2].columns[OT_random_index]]\n",
    "\n",
    "        expected_STA = gen_expected[0][gen_expected[0].columns[STA_random_index]]\n",
    "        expected_CR = gen_expected[1][gen_expected[1].columns[CR_random_index]]\n",
    "        expected_OT = gen_expected[2][gen_expected[2].columns[OT_random_index]]\n",
    "\n",
    "        IS_STA = gen_IS[0].loc[gen_IS[0].index[STA_random_index].to_numpy()]\n",
    "        IS_CR = gen_IS[1].loc[gen_IS[1].index[CR_random_index]]\n",
    "        IS_OT = gen_IS[2].loc[gen_IS[2].index[OT_random_index]]\n",
    "\n",
    "        a = pd.concat([counts_STA, counts_CR, counts_OT], axis=1)\n",
    "        b = pd.concat([expected_STA, expected_CR, expected_OT], axis=1)\n",
    "        c = pd.concat([IS_STA, IS_CR, IS_OT], axis=0)\n",
    "\n",
    "        patient_labels = a.columns\n",
    "\n",
    "        for i in range(len(STA_range)):\n",
    "            # leave only STA_range[i] STA patients\n",
    "            a_tmp = a.drop(patient_labels[range(n_STA - STA_range[i])], axis=1)\n",
    "            b_tmp = b.drop(patient_labels[range(n_STA - STA_range[i])], axis=1)\n",
    "            c_tmp = c.drop(patient_labels[range(n_STA - STA_range[i])], axis=0)\n",
    "            try:\n",
    "                d, e, f, datasets_to_save = experiment(a_tmp, b_tmp, c_tmp, n_CR=15, distribution=distribution, pool=pool)\n",
    "                mean_auc_results_origin[j, i] = d.mean()\n",
    "                mean_auc_results_expected[j, i] = e.mean()\n",
    "                mean_auc_results_filtered[j, i] = f.mean()\n",
    "                # datasets_to_save_filename = '{filename}-STA-{sta}-repeat-{j}-{uniqueID}.npz'.format(filename=filename, sta=STA_range[i], j=j, uniqueID=datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "                # np.savez(datasets_to_save_filename, datasets=datasets_to_save)\n",
    "            except Exception as e:  #! when STA number is too small, there is the PerfectSeparation error\n",
    "                print('Exception when ', STA_range[i], ' STA samples. Error: ', e)\n",
    "                mean_auc_results_origin[j, i] = np.nan\n",
    "                mean_auc_results_expected[j, i] = np.nan\n",
    "                mean_auc_results_filtered[j, i] = np.nan\n",
    "    return mean_auc_results_origin, mean_auc_results_expected, mean_auc_results_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_classification(n_transcripts, n_IS_effect, IS_effect, n_class_effect, class_effect_mean, STA_range, pool, filename):\n",
    "    n_repeats = 10 # pocet opakovani\n",
    "    n_genSTA = 12000 # pocet nagenerovanych STA vzorku\n",
    "    n_genCR = 100 # pocet nagenerovanych CR vzorku\n",
    "    n_genOT = 100 # pocet nagenerovanych OT vzorku\n",
    "\n",
    "    # Generate dataset\n",
    "    _, _, _, gen_origin, gen_expected, gen_IS = rna_seq_generator(\n",
    "        n_transcripts=n_transcripts,\n",
    "        distribution=Distribution.NEGATIVE_BINOMIAL, # POISON\n",
    "        n_STA=n_genSTA, n_CR=n_genCR, n_OT=n_genOT,\n",
    "        n_IS_effect=n_IS_effect, IS_effect=(IS_effect, IS_effect+0.01),  # IS effect\n",
    "        is_class_effect=n_class_effect > 0, n_class_effect=n_class_effect, class_effect=NormalDistributionParameters(class_effect_mean, 0.1)\n",
    "    )\n",
    "\n",
    "    # Compensate and classify\n",
    "    mean_auc_results_origin, mean_auc_results_expected, mean_auc_results_filtered = \\\n",
    "        experiment_iteration(STA_range, n_repeats,\n",
    "                             gen_origin, gen_expected, gen_IS,\n",
    "                             n_genSTA, n_genCR, n_genOT, \"Negative binomial\", # \"Negative binomial\" or \"Poisson\"\n",
    "                             pool, filename)\n",
    "\n",
    "    return mean_auc_results_origin, mean_auc_results_expected, mean_auc_results_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_repeats = 10 # pocet opakovani\n",
    "n_genSTA = 12000 # pocet nagenerovanych STA vzorku\n",
    "n_genCR = 100 # pocet nagenerovanych CR vzorku\n",
    "n_genOT = 100 # pocet nagenerovanych OT vzorku\n",
    "_, _, _, gen_origin, gen_expected, gen_IS = rna_seq_generator(\n",
    "     n_transcripts=10,\n",
    "    distribution=Distribution.NEGATIVE_BINOMIAL,  # POISSON\n",
    "    n_STA=n_genSTA, n_CR=n_genCR, n_OT=n_genOT,\n",
    "    n_IS_effect=3, IS_effect=(0.3, 0.3+0.01),  # IS effect\n",
    "    is_class_effect=4 > 0, n_class_effect=4, class_effect=NormalDistributionParameters(0.2, 0.1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new IS_effect_n_transcripts:  50\n",
      "new IS_effect:  0.5\n"
     ]
    }
   ],
   "source": [
    " # new: is class: 30 30 ; 20 20 , 20 10 ; 30 10, 30 20;; 50 20, 50 30, 50 50\n",
    "transcripts = [10000]\n",
    "class_effect_n_transcripts = [20, 30, 50]\n",
    "class_effect = [0.3]  # mean of normal distribution\n",
    "\n",
    "IS_effect_n_transcripts = [50]\n",
    "IS_effect = [0.5]  # coefficients beta1..beta3\n",
    "\n",
    "STA_range = [20, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "with Pool() as pool:\n",
    "    for t in transcripts:\n",
    "        for n_IS in IS_effect_n_transcripts:\n",
    "            print('new IS_effect_n_transcripts: ', n_IS)\n",
    "            for i in IS_effect:\n",
    "                print('new IS_effect: ', i)\n",
    "                for n_class in class_effect_n_transcripts:\n",
    "                    class_effect_list = [0.2] if n_class == 0 else class_effect\n",
    "                    for c in class_effect_list:\n",
    "                        params_str = '/{t}_{n_IS}_{i}_{n_class}_{c}_{dist}'.format(t=t, n_IS=n_IS, i=i, n_class=n_class, c=c, dist=data_distribution)\n",
    "                        filename = '' # foldername_generated_data + params_str\n",
    "\n",
    "                        if (len(saved_origin[t][n_IS][i][n_class][c]['STA_range']) > 0 and\n",
    "                            saved_origin[t][n_IS][i][n_class][c]['auc'].size > 0):\n",
    "                            print('WARNING: Dataset with parameters \\\"' + params_str + '\\\" already exists')\n",
    "                            continue\n",
    "\n",
    "                        mean_o, mean_e, mean_f = experiment_classification(t, n_IS, i, n_class, c, STA_range, pool, filename)\n",
    "                        saved_origin[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_origin[t][n_IS][i][n_class][c]['auc'] = mean_o\n",
    "\n",
    "                        saved_expected[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_expected[t][n_IS][i][n_class][c]['auc'] = mean_e\n",
    "\n",
    "                        saved_filtered[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_filtered[t][n_IS][i][n_class][c]['auc'] = mean_f\n",
    "\n",
    "                    np.savez(filename_auc_results_origin, auc_data=saved_origin)\n",
    "                    np.savez(filename_auc_results_expected, auc_data=saved_expected)\n",
    "                    np.savez(filename_auc_results_filtered, auc_data=saved_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_origin)\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_expected)\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_origin)\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_expected)\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_origin)\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_expected)\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_origin)\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_expected)\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from multiprocessing import Pool\n",
    "#\n",
    "# def f(x):\n",
    "#     return x*x\n",
    "#\n",
    "# if __name__ == '__main__':\n",
    "#     with Pool(5) as p:\n",
    "#         print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# if os.path.isfile(filename + '_origin.npz') or \\\n",
    "#         os.path.isfile(filename + '_expected.npz') or \\\n",
    "#         os.path.isfile(filename + '_filtered.npz') or \\\n",
    "#         os.path.isfile(filename + '_learnedbeta.npz'):\n",
    "#     print('Warning: Dataset with filename \\\"' + filename + '...\\\" already exists')\n",
    "#     continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
