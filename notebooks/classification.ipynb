{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Compensate and classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/karinabalagazova/Desktop/cvut/5.semestr/scientificProject/notebooks/..\")\n",
    "import os.path\n",
    "# from functions.experiment import experiment_iteration\n",
    "from functions.rnaseq_data_generator import rna_seq_generator, NormalDistributionParameters\n",
    "from utils.enums import Distribution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "\n",
    "from functions.saving_data import get_empty_auc_dataset\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Prepare to store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_distribution = 'neg-binomial' # or 'poisson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets will be stored in \"generated-data-neg-binomial-20210809-001025\" folder.\n"
     ]
    }
   ],
   "source": [
    "# Create folder to save generated data\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "foldername_generated_data = 'generated-data-' + data_distribution + '-' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "Path(foldername_generated_data).mkdir(parents=True, exist_ok=True)\n",
    "print('All datasets will be stored in \\\"' + foldername_generated_data + '\\\" folder.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: File with this name already exists!\n"
     ]
    }
   ],
   "source": [
    "# Get and save EMPTY dict for storing classification results\n",
    "data = get_empty_auc_dataset()\n",
    "filename_auc_results_origin = 'auc_results_origin_'+ data_distribution + '.npz'\n",
    "filename_auc_results_expected = 'auc_results_expected_'+ data_distribution + '.npz'\n",
    "filename_auc_results_filtered = 'auc_results_filtered_'+ data_distribution + '.npz'\n",
    "\n",
    "if os.path.isfile(filename_auc_results_origin) or \\\n",
    "        os.path.isfile(filename_auc_results_expected) or \\\n",
    "        os.path.isfile(filename_auc_results_filtered):\n",
    "    print('WARNING: File with this name already exists!')\n",
    "else:\n",
    "    np.savez(filename_auc_results_origin, auc_data=data)\n",
    "    np.savez(filename_auc_results_expected, auc_data=data)\n",
    "    np.savez(filename_auc_results_filtered, auc_data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Arrays for storing classification results\n",
    "saved_origin = np.load(filename_auc_results_origin, allow_pickle=True)\n",
    "saved_origin = saved_origin['auc_data'].item()\n",
    "\n",
    "saved_expected = np.load(filename_auc_results_expected, allow_pickle=True)\n",
    "saved_expected = saved_expected['auc_data'].item()\n",
    "\n",
    "saved_filtered = np.load(filename_auc_results_filtered, allow_pickle=True)\n",
    "saved_filtered = saved_filtered['auc_data'].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def learn_beta_poisson(df):\n",
    "    mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.Poisson(), data=df).fit()\n",
    "    return np.array([mp.params.x1, mp.params.x2, mp.params.x3])\n",
    "    \n",
    "def learn_beta_neg_binomial(df):\n",
    "    mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.NegativeBinomial(), data=df).fit()\n",
    "    return np.array([mp.params.x1, mp.params.x2, mp.params.x3])\n",
    "\n",
    "def compensation(counts, IS, t, n_CR, distribution, pool: Pool):\n",
    "    \"\"\"\n",
    "    IS compensation.\n",
    "\n",
    "    :param counts: Counts to be compensated.\n",
    "    :param IS: Array of immunosuppression intake (0 or 1).\n",
    "    :param t: Number of transcripts.\n",
    "    :param distribution: \"Poisson\" or \"Negative binomial\".\n",
    "    :param n_CR: Number of samples in CR class. First n_CR elements of counts must be of CR class.\n",
    "    \"\"\"\n",
    "    # leave only STA\n",
    "    STA_patients = counts.columns.str.startswith('STA')\n",
    "    STA_counts = counts.loc[:, STA_patients].to_numpy()\n",
    "    STA_IS = IS.loc[STA_patients]\n",
    "\n",
    "    # try to learn the beta1 parameters from STA class\n",
    "    learned_beta = np.zeros((3, t))\n",
    "    values = list()\n",
    "    for ind in range(t):\n",
    "        values.append(pd.DataFrame({\"x1\": STA_IS['IS1'].values.tolist(),\n",
    "                           \"x2\": STA_IS['IS2'].values.tolist(),\n",
    "                           \"x3\": STA_IS['IS3'].values.tolist(),\n",
    "                           \"y\": STA_counts[ind]}))\n",
    "\n",
    "    vs = pool.map(learn_beta_poisson, values) if distribution == \"Poisson\" else \\\n",
    "    pool.map(learn_beta_neg_binomial, values) if distribution == \"Negative binomial\" else \\\n",
    "        False\n",
    "\n",
    "    if not vs:\n",
    "        print('Something is bad with pool.map(...)')\n",
    "\n",
    "    for ind in range(t):\n",
    "        learned_beta[:, ind] = vs[ind]\n",
    "    \n",
    "    # leave only CR and OT classes for classification\n",
    "    OT_CR_counts = counts.loc[:, ~STA_patients].to_numpy(dtype=float)\n",
    "    OT_CR_IS = IS.loc[~STA_patients].values\n",
    "\n",
    "    # filter out IS from CR\n",
    "    OT_CR_counts[:, :n_CR] = OT_CR_counts[:, :n_CR] / np.exp(np.dot(OT_CR_IS[:n_CR], learned_beta).transpose())\n",
    "    OT_CR_counts = OT_CR_counts.transpose()\n",
    "    return OT_CR_counts, OT_CR_IS, learned_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(generated_counts, generated_expected_counts, generated_IS, n_CR: int, distribution, pool):\n",
    "    # counts generated with IS influence\n",
    "    counts, patients_labels, _ = preprocess_for_classification(generated_counts)\n",
    "\n",
    "    # counts generated with similar beta0, but without IS influence\n",
    "    expected_counts, _, _ = preprocess_for_classification(generated_expected_counts)\n",
    "\n",
    "    # IS compensation\n",
    "    t = generated_counts.shape[0]\n",
    "    filtered_counts, OT_CR_IS, learned_beta = compensation(generated_counts, generated_IS, t, n_CR, distribution, pool)\n",
    "\n",
    "    columns = [\"transcript\" + str(num) for num in range(counts.shape[1])]\n",
    "    y = pd.DataFrame(data=patients_labels)\n",
    "\n",
    "    datasets_to_save = dict()\n",
    "    datasets_to_save['learned_beta'] = learned_beta\n",
    "    datasets_to_save['y'] = y\n",
    "\n",
    "    # COUNTS\n",
    "    X = pd.DataFrame(data=counts, columns=columns)\n",
    "    results_origin = classify(X, y.values.ravel(), n_splits=10, n_repeats=1)\n",
    "    datasets_to_save['origin_X'] = X\n",
    "\n",
    "    # EXPECTED\n",
    "    X = pd.DataFrame(data=expected_counts, columns=columns)\n",
    "    results_expected = classify(X, y.values.ravel(), n_splits=10, n_repeats=1)\n",
    "    datasets_to_save['expected_X'] = X\n",
    "\n",
    "    # FILTERED\n",
    "    X = pd.DataFrame(data=filtered_counts, columns=columns)\n",
    "    results_filtered = classify(X, y.values.ravel(), n_splits=10, n_repeats=1)\n",
    "    datasets_to_save['filtered_X'] = X\n",
    "\n",
    "    return results_origin, results_expected, results_filtered, datasets_to_save\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from functions.classificator import classify\n",
    "from functions.data_preprocess import preprocess_for_classification\n",
    "\n",
    "def experiment_iteration(STA_range, n_repeats, gen_origin, gen_expected, gen_IS,\n",
    "                         n_genSTA, n_genCR, n_genOT,\n",
    "                         distribution, pool, filename):\n",
    "    n_STA = STA_range[-1]  # maximal number of STA patients\n",
    "\n",
    "    # arrays for AUC results\n",
    "    mean_auc_results_origin = np.zeros((n_repeats, len(STA_range)))\n",
    "    mean_auc_results_expected = np.zeros((n_repeats, len(STA_range)))\n",
    "    mean_auc_results_filtered = np.zeros((n_repeats, len(STA_range)))\n",
    "\n",
    "    for j in range(n_repeats):\n",
    "        STA_random_index = random.sample(range(n_genSTA), n_STA)\n",
    "        CR_random_index = random.sample(range(n_genCR), 15)\n",
    "        OT_random_index = random.sample(range(n_genOT), 15)\n",
    "\n",
    "        counts_STA = gen_origin[0][gen_origin[0].columns[STA_random_index]]\n",
    "        counts_CR = gen_origin[1][gen_origin[1].columns[CR_random_index]]\n",
    "        counts_OT = gen_origin[2][gen_origin[2].columns[OT_random_index]]\n",
    "\n",
    "        expected_STA = gen_expected[0][gen_expected[0].columns[STA_random_index]]\n",
    "        expected_CR = gen_expected[1][gen_expected[1].columns[CR_random_index]]\n",
    "        expected_OT = gen_expected[2][gen_expected[2].columns[OT_random_index]]\n",
    "\n",
    "        IS_STA = gen_IS[0].loc[gen_IS[0].index[STA_random_index].to_numpy()]\n",
    "        IS_CR = gen_IS[1].loc[gen_IS[1].index[CR_random_index]]\n",
    "        IS_OT = gen_IS[2].loc[gen_IS[2].index[OT_random_index]]\n",
    "\n",
    "        a = pd.concat([counts_STA, counts_CR, counts_OT], axis=1)\n",
    "        b = pd.concat([expected_STA, expected_CR, expected_OT], axis=1)\n",
    "        c = pd.concat([IS_STA, IS_CR, IS_OT], axis=0)\n",
    "\n",
    "        patient_labels = a.columns\n",
    "\n",
    "        for i in range(len(STA_range)):\n",
    "            # leave only STA_range[i] STA patients\n",
    "            a_tmp = a.drop(patient_labels[range(n_STA - STA_range[i])], axis=1)\n",
    "            b_tmp = b.drop(patient_labels[range(n_STA - STA_range[i])], axis=1)\n",
    "            c_tmp = c.drop(patient_labels[range(n_STA - STA_range[i])], axis=0)\n",
    "            try:\n",
    "                d, e, f, datasets_to_save = experiment(a_tmp, b_tmp, c_tmp, n_CR=15, distribution=distribution, pool=pool)\n",
    "                mean_auc_results_origin[j, i] = d.mean()\n",
    "                mean_auc_results_expected[j, i] = e.mean()\n",
    "                mean_auc_results_filtered[j, i] = f.mean()\n",
    "                datasets_to_save_filename = '{filename}-STA-{sta}-repeat-{j}-{uniqueID}.npz'.format(filename=filename, sta=STA_range[i], j=j, uniqueID=datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "                np.savez(datasets_to_save_filename, datasets=datasets_to_save)\n",
    "            except Exception as e:  #! when STA number is too small, there is the PerfectSeparation error\n",
    "                print('Exception when ', STA_range[i], ' STA samples. Error: ', e)\n",
    "                mean_auc_results_origin[j, i] = np.nan\n",
    "                mean_auc_results_expected[j, i] = np.nan\n",
    "                mean_auc_results_filtered[j, i] = np.nan\n",
    "    return mean_auc_results_origin, mean_auc_results_expected, mean_auc_results_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def experiment_classification(n_transcripts, n_IS_effect, IS_effect, n_class_effect, class_effect_mean, STA_range, pool, filename):\n",
    "    n_repeats = 10 # pocet opakovani\n",
    "    n_genSTA = 12000 # pocet nagenerovanych STA vzorku\n",
    "    n_genCR = 100 # pocet nagenerovanych CR vzorku\n",
    "    n_genOT = 100 # pocet nagenerovanych OT vzorku\n",
    "\n",
    "    # Generate dataset\n",
    "    _, _, _, gen_origin, gen_expected, gen_IS = rna_seq_generator(\n",
    "        n_transcripts=n_transcripts,\n",
    "        distribution=Distribution.NEGATIVE_BINOMIAL,\n",
    "        n_STA=n_genSTA, n_CR=n_genCR, n_OT=n_genOT,\n",
    "        n_IS_effect=n_IS_effect, IS_effect=(IS_effect, IS_effect+0.01),  # IS effect\n",
    "        is_class_effect=n_class_effect > 0, n_class_effect=n_class_effect, class_effect=NormalDistributionParameters(class_effect_mean, 0.1)\n",
    "    )\n",
    "\n",
    "    # Compensate and classify\n",
    "    mean_auc_results_origin, mean_auc_results_expected, mean_auc_results_filtered = \\\n",
    "        experiment_iteration(STA_range, n_repeats,\n",
    "                             gen_origin, gen_expected, gen_IS,\n",
    "                             n_genSTA, n_genCR, n_genOT, \"Negative binomial\", # \"Negative binomial\" or \"Poisson\"\n",
    "                             pool, filename)\n",
    "    return mean_auc_results_origin, mean_auc_results_expected, mean_auc_results_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new IS_effect_n_transcripts:  5\n",
      "new IS_effect:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-2:\n",
      "Process ForkPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Process ForkPoolWorker-3:\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/var/folders/_p/6xmdmxy54p77x6qjslskgcbc0000gn/T/ipykernel_82271/1135294581.py\", line 8, in learn_beta_neg_binomial\n",
      "    mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.NegativeBinomial(), data=df).fit()\n",
      "  File \"/Library/Python/3.7/site-packages/statsmodels/genmod/generalized_linear_model.py\", line 1065, in fit\n",
      "    cov_kwds=cov_kwds, use_t=use_t, **kwargs)\n",
      "  File \"/var/folders/_p/6xmdmxy54p77x6qjslskgcbc0000gn/T/ipykernel_82271/1135294581.py\", line 8, in learn_beta_neg_binomial\n",
      "    mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.NegativeBinomial(), data=df).fit()\n",
      "  File \"/Library/Python/3.7/site-packages/statsmodels/genmod/generalized_linear_model.py\", line 1170, in _fit_irls\n",
      "    mu = self.family.starting_mu(self.endog)\n",
      "  File \"/Library/Python/3.7/site-packages/statsmodels/base/model.py\", line 195, in from_formula\n",
      "    mod = cls(endog, exog, *args, **kwargs)\n",
      "  File \"/Library/Python/3.7/site-packages/statsmodels/genmod/families/family.py\", line 112, in starting_mu\n",
      "    return (y + y.mean())/2.\n",
      "  File \"/Library/Python/3.7/site-packages/statsmodels/genmod/generalized_linear_model.py\", line 314, in __init__\n",
      "    var_weights=var_weights, **kwargs)\n",
      "  File \"/Library/Python/3.7/site-packages/statsmodels/base/model.py\", line 237, in __init__\n",
      "    super(LikelihoodModel, self).__init__(endog, exog, **kwargs)\n",
      "  File \"/Library/Python/3.7/site-packages/numpy/core/_methods.py\", line 161, in _mean\n",
      "    if isinstance(ret, mu.ndarray):\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/var/folders/_p/6xmdmxy54p77x6qjslskgcbc0000gn/T/ipykernel_82271/1135294581.py\", line 9, in learn_beta_neg_binomial\n",
      "    return np.array([mp.params.x1, mp.params.x2, mp.params.x3])\n",
      "  File \"/Library/Python/3.7/site-packages/statsmodels/base/wrapper.py\", line 40, in __getattribute__\n",
      "    obj = data.wrap_output(obj, how=how)\n",
      "  File \"/Library/Python/3.7/site-packages/statsmodels/base/data.py\", line 439, in wrap_output\n",
      "    return self.attach_columns(obj)\n",
      "  File \"/Library/Python/3.7/site-packages/statsmodels/base/data.py\", line 559, in attach_columns\n",
      "    return Series(result, index=self.param_names)\n",
      "  File \"/Library/Python/3.7/site-packages/pandas/core/series.py\", line 244, in __init__\n",
      "    index = ensure_index(index)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Python/3.7/site-packages/pandas/core/indexes/base.py\", line 5623, in ensure_index\n",
      "    return Index(index_like)\n",
      "  File \"/Library/Python/3.7/site-packages/pandas/core/indexes/base.py\", line 404, in __new__\n",
      "    new_data, dtype=new_dtype, copy=False, name=name, **kwargs\n",
      "  File \"/Library/Python/3.7/site-packages/pandas/core/indexes/base.py\", line 346, in __new__\n",
      "    elif is_period_dtype(data_dtype) or is_period_dtype(dtype):\n",
      "  File \"/Library/Python/3.7/site-packages/pandas/core/dtypes/common.py\", line 489, in is_period_dtype\n",
      "    return PeriodDtype.is_dtype(arr_or_dtype)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n",
      "    return list(map(*args))\n",
      "  File \"/var/folders/_p/6xmdmxy54p77x6qjslskgcbc0000gn/T/ipykernel_82271/1135294581.py\", line 9, in learn_beta_neg_binomial\n",
      "    return np.array([mp.params.x1, mp.params.x2, mp.params.x3])\n",
      "  File \"/Library/Python/3.7/site-packages/statsmodels/base/wrapper.py\", line 37, in __getattribute__\n",
      "    if how and isinstance(how, tuple):\n",
      "  File \"/Library/Python/3.7/site-packages/pandas/core/dtypes/dtypes.py\", line 925, in is_dtype\n",
      "    return super().is_dtype(dtype)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<timed exec>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n",
      "\u001B[0;32m/var/folders/_p/6xmdmxy54p77x6qjslskgcbc0000gn/T/ipykernel_82271/2380727223.py\u001B[0m in \u001B[0;36mexperiment_classification\u001B[0;34m(n_transcripts, n_IS_effect, IS_effect, n_class_effect, class_effect_mean, STA_range, pool, filename)\u001B[0m\n\u001B[1;32m     19\u001B[0m                              \u001B[0mgen_origin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgen_expected\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgen_IS\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m                              \u001B[0mn_genSTA\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_genCR\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_genOT\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"Negative binomial\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;31m# \"Negative binomial\" or \"Poisson\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m                              pool, filename)\n\u001B[0m\u001B[1;32m     22\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmean_auc_results_origin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmean_auc_results_expected\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmean_auc_results_filtered\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/_p/6xmdmxy54p77x6qjslskgcbc0000gn/T/ipykernel_82271/2151592112.py\u001B[0m in \u001B[0;36mexperiment_iteration\u001B[0;34m(STA_range, n_repeats, gen_origin, gen_expected, gen_IS, n_genSTA, n_genCR, n_genOT, distribution, pool, filename)\u001B[0m\n\u001B[1;32m     79\u001B[0m             \u001B[0mc_tmp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpatient_labels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mn_STA\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mSTA_range\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     80\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 81\u001B[0;31m                 \u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdatasets_to_save\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mexperiment\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma_tmp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mb_tmp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mc_tmp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_CR\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m15\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdistribution\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdistribution\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpool\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mpool\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     82\u001B[0m                 \u001B[0mmean_auc_results_origin\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0md\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     83\u001B[0m                 \u001B[0mmean_auc_results_expected\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mj\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmean\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/_p/6xmdmxy54p77x6qjslskgcbc0000gn/T/ipykernel_82271/2151592112.py\u001B[0m in \u001B[0;36mexperiment\u001B[0;34m(generated_counts, generated_expected_counts, generated_IS, n_CR, distribution, pool)\u001B[0m\n\u001B[1;32m      8\u001B[0m     \u001B[0;31m# IS compensation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m     \u001B[0mt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mgenerated_counts\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m     \u001B[0mfiltered_counts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mOT_CR_IS\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlearned_beta\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompensation\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgenerated_counts\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgenerated_IS\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mt\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_CR\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdistribution\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpool\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[0mcolumns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"transcript\"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mnum\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcounts\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/_p/6xmdmxy54p77x6qjslskgcbc0000gn/T/ipykernel_82271/1135294581.py\u001B[0m in \u001B[0;36mcompensation\u001B[0;34m(counts, IS, t, n_CR, distribution, pool)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[0mvs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpool\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlearn_beta_poisson\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdistribution\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"Poisson\"\u001B[0m \u001B[0;32melse\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 36\u001B[0;31m     \u001B[0mpool\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlearn_beta_neg_binomial\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalues\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdistribution\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"Negative binomial\"\u001B[0m \u001B[0;32melse\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     37\u001B[0m         \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     38\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001B[0m in \u001B[0;36mmap\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    266\u001B[0m         \u001B[0;32min\u001B[0m \u001B[0ma\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mthat\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mreturned\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    267\u001B[0m         '''\n\u001B[0;32m--> 268\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_map_async\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmapstar\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    269\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    270\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mstarmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mchunksize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    649\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    650\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 651\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    652\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mready\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    653\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/multiprocessing/pool.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    646\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    647\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 648\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_event\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    649\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    650\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    550\u001B[0m             \u001B[0msignaled\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_flag\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    551\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0msignaled\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 552\u001B[0;31m                 \u001B[0msignaled\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cond\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    553\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0msignaled\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    554\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    294\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m    \u001B[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    295\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 296\u001B[0;31m                 \u001B[0mwaiter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    297\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    298\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#\n",
    "# transcripts = [10, 100, 1000, 10000]\n",
    "# class_effect_n_transcripts = [0, 2, 5, 10]\n",
    "# class_effect = [0.2, 0.3, 0.4]  # mean of normal distribution\n",
    "#\n",
    "# IS_effect_n_transcripts = [2]#, 5, 10]\n",
    "# IS_effect = [0.3]#, 0.5, 0.9]  # coefficients beta1..beta3\n",
    "\n",
    "transcripts = [10000]\n",
    "class_effect_n_transcripts = [0, 5, 10, 20]\n",
    "class_effect = [0.3, 0.4]  # mean of normal distribution\n",
    "\n",
    "IS_effect_n_transcripts = [5, 10]\n",
    "IS_effect = [0.5, 0.9]  # coefficients beta1..beta3\n",
    "\n",
    "STA_range = [20, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "\n",
    "with Pool() as pool:\n",
    "    for t in transcripts:\n",
    "        for n_IS in IS_effect_n_transcripts:\n",
    "            print('new IS_effect_n_transcripts: ', n_IS)\n",
    "            for i in IS_effect:\n",
    "                print('new IS_effect: ', i)\n",
    "                for n_class in class_effect_n_transcripts:\n",
    "                    if n_class == 0:\n",
    "                        c = 0.2\n",
    "                        filename = foldername_generated_data + '/{t}_{n_IS}_{i}_{n_class}_{dist}'.format(t=t, n_IS=n_IS, i=i, n_class=n_class, dist=data_distribution)\n",
    "                        mean_o, mean_e, mean_f = experiment_classification(t, n_IS, i, n_class, c, STA_range, pool, filename)\n",
    "                        saved_origin[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_origin[t][n_IS][i][n_class][c]['auc'] = mean_o\n",
    "\n",
    "                        saved_expected[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_expected[t][n_IS][i][n_class][c]['auc'] = mean_e\n",
    "\n",
    "                        saved_filtered[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_filtered[t][n_IS][i][n_class][c]['auc'] = mean_f\n",
    "                    else:\n",
    "                        for c in class_effect:\n",
    "                            filename = foldername_generated_data + '/{t}_{n_IS}_{i}_{n_class}_{c}_{dist}'.format(t=t, n_IS=n_IS, i=i, n_class=n_class, c=c, dist=data_distribution)\n",
    "#                             if os.path.isfile(filename + '_origin.npz') or \\\n",
    "#                                     os.path.isfile(filename + '_expected.npz') or \\\n",
    "#                                     os.path.isfile(filename + '_filtered.npz') or \\\n",
    "#                                     os.path.isfile(filename + '_learnedbeta.npz'):\n",
    "#                                 print('Warning: Dataset with filename \\\"' + filename + '...\\\" already exists')\n",
    "#                                 continue\n",
    "\n",
    "                            if (len(saved_origin[t][n_IS][i][n_class][c]['STA_range']) > 0 and \\\n",
    "                                saved_origin[t][n_IS][i][n_class][c]['auc'].size > 0):\n",
    "                                print('WARNING: Dataset with parameters \\\"' + filename + '...\\\" already exists')\n",
    "                                continue\n",
    "        \n",
    "                            mean_o, mean_e, mean_f = experiment_classification(t, n_IS, i, n_class, c, STA_range, pool, filename)\n",
    "                            saved_origin[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                            saved_origin[t][n_IS][i][n_class][c]['auc'] = mean_o\n",
    "\n",
    "                            saved_expected[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                            saved_expected[t][n_IS][i][n_class][c]['auc'] = mean_e\n",
    "\n",
    "                            saved_filtered[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                            saved_filtered[t][n_IS][i][n_class][c]['auc'] = mean_f\n",
    "\n",
    "                    np.savez(filename_auc_results_origin, auc_data=saved_origin)\n",
    "                    np.savez(filename_auc_results_expected, auc_data=saved_expected)\n",
    "                    np.savez(filename_auc_results_filtered, auc_data=saved_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_origin)\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_expected)\n",
    "np.savez('final-' + filename_auc_results_origin, auc_data=saved_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}