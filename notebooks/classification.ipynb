{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/karinabalagazova/Desktop/cvut/5.semestr/scientificProject/notebooks/..\")\n",
    "import os.path\n",
    "# from functions.experiment import experiment_iteration\n",
    "from functions.rnaseq_data_generator import rna_seq_generator, NormalDistributionParameters\n",
    "from utils.enums import Distribution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "\n",
    "from functions.saving_data import get_empty_auc_dataset\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare to store data into array\n",
    "STA_range = [20, 50, 100, 200, 500, 1000, 2000, 5000]\n",
    "data = get_empty_auc_dataset(STA_range, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "# np.savez('auc_results_origin.npz', auc_data=data)\n",
    "saved_origin = np.load('auc_results_origin.npz', allow_pickle=True)\n",
    "saved_origin = saved_origin['auc_data'].item()\n",
    "\n",
    "# np.savez('auc_results_expected.npz', auc_data=data)\n",
    "saved_expected = np.load('auc_results_expected.npz', allow_pickle=True)\n",
    "saved_expected = saved_expected['auc_data'].item()\n",
    "\n",
    "# np.savez('auc_results_filtered.npz', auc_data=data)\n",
    "saved_filtered = np.load('auc_results_filtered.npz', allow_pickle=True)\n",
    "saved_filtered = saved_filtered['auc_data'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def work_bitch(df):\n",
    "#     if distribution == \"Poisson\":\n",
    "    mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.Poisson(), data=df).fit()\n",
    "#     elif distribution == \"Negative binomial\":\n",
    "#     mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.NegativeBinomial(), data=df).fit()\n",
    "    return np.array([mp.params.x1, mp.params.x2, mp.params.x3])\n",
    "#     else:\n",
    "#         print(\"Unknown distribution\")\n",
    "#         return\n",
    "\n",
    "def compensation(counts, IS, t, n_CR, distribution, pool, filename):\n",
    "    \"\"\"\n",
    "    IS compensation.\n",
    "\n",
    "    :param counts: Counts to be compensated.\n",
    "    :param IS: Array of immunosuppression intake (0 or 1).\n",
    "    :param t: Number of transcripts.\n",
    "    :param distribution: \"Poisson\" or \"Negative binomial\".\n",
    "    :param n_CR: Number of samples in CR class. First n_CR elements of counts must be of CR class.\n",
    "    \"\"\"\n",
    "    # leave only STA\n",
    "    STA_patients = counts.columns.str.startswith('STA')\n",
    "    STA_counts = counts.loc[:, STA_patients].to_numpy()\n",
    "    STA_IS = IS.loc[STA_patients]\n",
    "\n",
    "    # try to learn the beta1 parameters from STA class\n",
    "    # TODO: save learned_beta and use it to speed up code\n",
    "    learned_beta = np.zeros((3, t))\n",
    "    values = list()\n",
    "    for ind in range(t):\n",
    "        values.append(pd.DataFrame({\"x1\": STA_IS['IS1'].values.tolist(),\n",
    "                           \"x2\": STA_IS['IS2'].values.tolist(),\n",
    "                           \"x3\": STA_IS['IS3'].values.tolist(),\n",
    "                           \"y\": STA_counts[ind]}))\n",
    "\n",
    "#     with Pool() as pool:\n",
    "    vs = pool.map(work_bitch, values)\n",
    "\n",
    "    for ind in range(t):\n",
    "        learned_beta[:, ind] = vs[ind]\n",
    "#     return\n",
    "#         df = pd.DataFrame({\"x1\": STA_IS['IS1'].values.tolist(),\n",
    "#                            \"x2\": STA_IS['IS2'].values.tolist(),\n",
    "#                            \"x3\": STA_IS['IS3'].values.tolist(),\n",
    "#                            \"y\": STA_counts[ind]})\n",
    "#         if distribution == \"Poisson\":\n",
    "#             mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.Poisson(), data=df).fit()\n",
    "#         elif distribution == \"Negative binomial\":\n",
    "#             mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.NegativeBinomial(), data=df).fit()\n",
    "#         else:\n",
    "#             print(\"Unknown distribution\")\n",
    "#             return\n",
    "#         learned_beta[:, ind] = np.array([mp.params.x1, mp.params.x2, mp.params.x3])\n",
    "\n",
    "\n",
    "    np.savez('{filename}_learnedbeta.npz'.format(filename=filename), beta=learned_beta)\n",
    "    \n",
    "    # leave only CR and OT classes for classification\n",
    "    OT_CR_counts = counts.loc[:, ~STA_patients].to_numpy(dtype=float)\n",
    "    OT_CR_IS = IS.loc[~STA_patients].values\n",
    "\n",
    "    # filter out IS from CR\n",
    "    OT_CR_counts[:, :n_CR] = OT_CR_counts[:, :n_CR] / np.exp(np.dot(OT_CR_IS[:n_CR], learned_beta).transpose())\n",
    "    OT_CR_counts = OT_CR_counts.transpose()\n",
    "    return OT_CR_counts, OT_CR_IS, learned_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(generated_counts, generated_expected_counts, generated_IS, n_CR: int, distribution, pool, filename):\n",
    "    # counts generated with IS influence\n",
    "    counts, patients_labels, _ = preprocess_for_classification(generated_counts)\n",
    "\n",
    "    # counts generated with similar beta0, but without IS influence\n",
    "    expected_counts, _, _ = preprocess_for_classification(generated_expected_counts)\n",
    "\n",
    "    # IS compensation\n",
    "    t = generated_counts.shape[0]\n",
    "    filtered_counts, OT_CR_IS, learned_beta = compensation(generated_counts, generated_IS, t, n_CR, distribution, pool, filename)\n",
    "\n",
    "    columns = [\"transcript\" + str(num) for num in range(counts.shape[1])]\n",
    "    y = patients_labels\n",
    "\n",
    "    # COUNTS\n",
    "    X = pd.DataFrame(data=counts, columns=columns)\n",
    "    y = pd.DataFrame(data=y)\n",
    "    y.head()\n",
    "    results1 = classify(X, y, n_splits=10, n_repeats=1)\n",
    "    np.savez('{filename}_origin.npz'.format(filename=filename), X=X, y=y)\n",
    "\n",
    "    # EXPECTED\n",
    "    X = pd.DataFrame(data=expected_counts, columns=columns)\n",
    "    y = pd.DataFrame(data=y)\n",
    "    y.head()\n",
    "    results2 = classify(X, y, n_splits=10, n_repeats=1)\n",
    "    np.savez('{filename}_expected.npz'.format(filename=filename), X=X, y=y)\n",
    "\n",
    "    # FILTERED\n",
    "    X = pd.DataFrame(data=filtered_counts, columns=columns)\n",
    "    y = pd.DataFrame(data=y)\n",
    "    y.head()\n",
    "    results3 = classify(X, y, n_splits=10, n_repeats=1)\n",
    "    np.savez('{filename}_filtered.npz'.format(filename=filename), X=X, y=y)\n",
    "\n",
    "    return results1, results2, results3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from functions.classificator import classify\n",
    "from functions.data_preprocess import preprocess_for_classification\n",
    "\n",
    "def experiment_iteration(STA_range, n_repeats, gen_origin, gen_expected, gen_IS,\n",
    "                         n_genSTA, n_genCR, n_genOT,\n",
    "                         distribution, pool, filename):\n",
    "    n_STA = STA_range[-1]  # maximal number of STA patients\n",
    "\n",
    "    # arrays for AUC results\n",
    "    mean_auc_results_origin = np.zeros((n_repeats, len(STA_range)))\n",
    "    mean_auc_results_expected = np.zeros((n_repeats, len(STA_range)))\n",
    "    mean_auc_results_filtered = np.zeros((n_repeats, len(STA_range)))\n",
    "\n",
    "    for j in range(n_repeats):\n",
    "        STA_random_index = random.sample(range(n_genSTA), n_STA)\n",
    "        CR_random_index = random.sample(range(n_genCR), 15)\n",
    "        OT_random_index = random.sample(range(n_genOT), 15)\n",
    "\n",
    "        counts_STA = gen_origin[0][gen_origin[0].columns[STA_random_index]]\n",
    "        counts_CR = gen_origin[1][gen_origin[1].columns[CR_random_index]]\n",
    "        counts_OT = gen_origin[2][gen_origin[2].columns[OT_random_index]]\n",
    "\n",
    "        expected_STA = gen_expected[0][gen_expected[0].columns[STA_random_index]]\n",
    "        expected_CR = gen_expected[1][gen_expected[1].columns[CR_random_index]]\n",
    "        expected_OT = gen_expected[2][gen_expected[2].columns[OT_random_index]]\n",
    "\n",
    "        IS_STA = gen_IS[0].loc[gen_IS[0].index[STA_random_index].to_numpy()]\n",
    "        IS_CR = gen_IS[1].loc[gen_IS[1].index[CR_random_index]]\n",
    "        IS_OT = gen_IS[2].loc[gen_IS[2].index[OT_random_index]]\n",
    "\n",
    "        a = pd.concat([counts_STA, counts_CR, counts_OT], axis=1)\n",
    "        b = pd.concat([expected_STA, expected_CR, expected_OT], axis=1)\n",
    "        c = pd.concat([IS_STA, IS_CR, IS_OT], axis=0)\n",
    "\n",
    "        patient_labels = a.columns\n",
    "\n",
    "        for i in range(len(STA_range)):\n",
    "            # leave only STA_range[i] STA patients\n",
    "            a_tmp = a.drop(patient_labels[range(n_STA - STA_range[i])], axis=1)\n",
    "            b_tmp = b.drop(patient_labels[range(n_STA - STA_range[i])], axis=1)\n",
    "            c_tmp = c.drop(patient_labels[range(n_STA - STA_range[i])], axis=0)\n",
    "            try:\n",
    "                d, e, f = experiment(a_tmp, b_tmp, c_tmp, n_CR=15, distribution=distribution, pool=pool, filename=filename)\n",
    "                mean_auc_results_origin[j, i] = d.mean()\n",
    "                mean_auc_results_expected[j, i] = e.mean()\n",
    "                mean_auc_results_filtered[j, i] = f.mean()\n",
    "            except Exception as e:  #! when STA number is too small, there are the PerfectSeparation error\n",
    "                print('Exception when ', STA_range[i], ' STA samples. Error: ', e)\n",
    "                mean_auc_results_origin[j, i] = np.nan\n",
    "                mean_auc_results_expected[j, i] = np.nan\n",
    "                mean_auc_results_filtered[j, i] = np.nan\n",
    "    return mean_auc_results_origin, mean_auc_results_expected, mean_auc_results_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def experiment_classification(n_transcripts, n_IS_effect, IS_effect, n_class_effect, class_effect_mean, STA_range, pool, filename):\n",
    "    n_repeats = 10\n",
    "    n_genSTA = 7000 # pocet nagenerovanych STA\n",
    "    n_genCR = 100\n",
    "    n_genOT = 100\n",
    "    _, _, _, gen_origin, gen_expected, gen_IS = rna_seq_generator(\n",
    "        n_transcripts=n_transcripts,\n",
    "        distribution=Distribution.POISSON, #\"Negative binomial\",\n",
    "        n_STA=n_genSTA, n_CR=n_genCR, n_OT=n_genOT,\n",
    "        n_IS_effect=n_IS_effect, IS_effect=(IS_effect, IS_effect+0.01),  # IS effect\n",
    "        is_class_effect=n_class_effect > 0, n_class_effect=n_class_effect, class_effect=NormalDistributionParameters(class_effect_mean, 0.1)\n",
    "    )\n",
    "    mean_auc_results_origin, mean_auc_results_expected, mean_auc_results_filtered = \\\n",
    "        experiment_iteration(STA_range, n_repeats,\n",
    "                             gen_origin, gen_expected, gen_IS,\n",
    "                             n_genSTA, n_genCR, n_genOT, \"Poisson\", pool, filename) #\"Negative binomial\")\n",
    "    return mean_auc_results_origin, mean_auc_results_expected, mean_auc_results_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new IS_effect_n_transcripts:  2\n",
      "new IS_effect:  0.3\n",
      "Warning: Dataset with filename \"generateddata04_08/10_2_0.3_2_0.2\" already exists\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#\n",
    "# transcripts = [10, 100, 1000, 10000]\n",
    "# class_effect_n_transcripts = [0, 2, 5, 10]\n",
    "# class_effect = [0.2, 0.3, 0.4]  # mean of normal distribution\n",
    "#\n",
    "# IS_effect_n_transcripts = [2]#, 5, 10]\n",
    "# IS_effect = [0.3]#, 0.5, 0.9]  # coefficients beta1..beta3\n",
    "\n",
    "transcripts = [10000]\n",
    "class_effect_n_transcripts = [0, 5, 10, 20]\n",
    "class_effect = [0.3, 0.4]  # mean of normal distribution\n",
    "\n",
    "IS_effect_n_transcripts = [5, 10]\n",
    "IS_effect = [0.5, 0.9]  # coefficients beta1..beta3\n",
    "with Pool() as pool:\n",
    "    for t in transcripts:\n",
    "        for n_IS in IS_effect_n_transcripts:\n",
    "            print('new IS_effect_n_transcripts: ', n_IS)\n",
    "            for i in IS_effect:\n",
    "                print('new IS_effect: ', i)\n",
    "                for n_class in class_effect_n_transcripts:\n",
    "                    if n_class == 0:\n",
    "                        c = 0.2\n",
    "                        filename = 'generateddata06_08/{t}_{n_IS}_{i}_{n_class}_poisson'.format(t=t, n_IS=n_IS, i=i, n_class=n_class)\n",
    "                        mean_o, mean_e, mean_f = experiment_classification(t, n_IS, i, n_class, c, STA_range, pool, filename)\n",
    "                        saved_origin[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_origin[t][n_IS][i][n_class][c]['auc'] = mean_o\n",
    "\n",
    "                        saved_expected[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_expected[t][n_IS][i][n_class][c]['auc'] = mean_e\n",
    "\n",
    "                        saved_filtered[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_filtered[t][n_IS][i][n_class][c]['auc'] = mean_f\n",
    "                    else:\n",
    "                        for c in class_effect:\n",
    "                            STA_range = [20, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "                            \n",
    "                            filename = 'generateddata06_08/{t}_{n_IS}_{i}_{n_class}_{c}_poisson'.format(t=t, n_IS=n_IS, i=i, n_class=n_class, c=c)\n",
    "                            if os.path.isfile(filename + '_origin.npz') or \\\n",
    "                                    os.path.isfile(filename + '_expected.npz') or \\\n",
    "                                    os.path.isfile(filename + '_filtered.npz') or \\\n",
    "                                    os.path.isfile(filename + '_learnedbeta.npz'):\n",
    "                                print('Warning: Dataset with filename \\\"' + filename + '\\\" already exists')\n",
    "                                continue\n",
    "\n",
    "                            print('a')\n",
    "                            mean_o, mean_e, mean_f = experiment_classification(t, n_IS, i, n_class, c, STA_range, pool, filename)\n",
    "                            saved_origin[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                            saved_origin[t][n_IS][i][n_class][c]['auc'] = mean_o\n",
    "\n",
    "                            saved_expected[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                            saved_expected[t][n_IS][i][n_class][c]['auc'] = mean_e\n",
    "\n",
    "                            saved_filtered[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                            saved_filtered[t][n_IS][i][n_class][c]['auc'] = mean_f\n",
    "\n",
    "                np.savez('auc_results_origin.npz', auc_data=saved_origin)\n",
    "                np.savez('auc_results_expected.npz', auc_data=saved_expected)\n",
    "                np.savez('auc_results_filtered.npz', auc_data=saved_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "np.savez('auc_results_origin5-poisson.npz', auc_data=saved_origin)\n",
    "np.savez('auc_results_expected5-poisson.npz', auc_data=saved_expected)\n",
    "np.savez('auc_results_filtered5-poisson.npz', auc_data=saved_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}