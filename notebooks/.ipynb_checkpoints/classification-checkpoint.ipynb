{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/karinabalagazova/Desktop/cvut/5.semestr/scientificProject/notebooks/..\")\n",
    "\n",
    "# from functions.experiment import experiment_iteration\n",
    "from functions.rnaseq_data_generator import rna_seq_generator, NormalDistributionParameters\n",
    "from utils.enums import Distribution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "\n",
    "from functions.saving_data import get_empty_auc_dataset\n",
    "import time\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare to store data into array\n",
    "STA_range = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000]\n",
    "data = get_empty_auc_dataset(STA_range, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "np.savez('auc_results_origin.npz', auc_data=data)\n",
    "saved_origin = np.load('auc_results_origin.npz', allow_pickle=True)\n",
    "saved_origin = saved_origin['auc_data'].item()\n",
    "\n",
    "np.savez('auc_results_expected.npz', auc_data=data)\n",
    "saved_expected = np.load('auc_results_expected.npz', allow_pickle=True)\n",
    "saved_expected = saved_expected['auc_data'].item()\n",
    "\n",
    "np.savez('auc_results_filtered.npz', auc_data=data)\n",
    "saved_filtered = np.load('auc_results_filtered.npz', allow_pickle=True)\n",
    "saved_filtered = saved_filtered['auc_data'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "def work_bitch(df):\n",
    "#     if distribution == \"Poisson\":\n",
    "#         mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.Poisson(), data=df).fit()\n",
    "#     elif distribution == \"Negative binomial\":\n",
    "    mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.NegativeBinomial(), data=df).fit()\n",
    "    return np.array([mp.params.x1, mp.params.x2, mp.params.x3])\n",
    "#     else:\n",
    "#         print(\"Unknown distribution\")\n",
    "#         return\n",
    "\n",
    "def compensation(counts, IS, t, n_CR, distribution, pool, filename):\n",
    "    \"\"\"\n",
    "    IS compensation.\n",
    "\n",
    "    :param counts: Counts to be compensated.\n",
    "    :param IS: Array of immunosuppression intake (0 or 1).\n",
    "    :param t: Number of transcripts.\n",
    "    :param distribution: \"Poisson\" or \"Negative binomial\".\n",
    "    :param n_CR: Number of samples in CR class. First n_CR elements of counts must be of CR class.\n",
    "    \"\"\"\n",
    "    # leave only STA\n",
    "    STA_patients = counts.columns.str.startswith('STA')\n",
    "    STA_counts = counts.loc[:, STA_patients].to_numpy()\n",
    "    STA_IS = IS.loc[STA_patients]\n",
    "\n",
    "    # try to learn the beta1 parameters from STA class\n",
    "    # TODO: save learned_beta and use it to speed up code\n",
    "    learned_beta = np.zeros((3, t))\n",
    "    values = list()\n",
    "    for ind in range(t):\n",
    "        values.append(pd.DataFrame({\"x1\": STA_IS['IS1'].values.tolist(),\n",
    "                           \"x2\": STA_IS['IS2'].values.tolist(),\n",
    "                           \"x3\": STA_IS['IS3'].values.tolist(),\n",
    "                           \"y\": STA_counts[ind]}))\n",
    "\n",
    "#     with Pool() as pool:\n",
    "    vs = pool.map(work_bitch, values)\n",
    "\n",
    "    for ind in range(t):\n",
    "        learned_beta[:, ind] = vs[ind]\n",
    "#     return\n",
    "#         df = pd.DataFrame({\"x1\": STA_IS['IS1'].values.tolist(),\n",
    "#                            \"x2\": STA_IS['IS2'].values.tolist(),\n",
    "#                            \"x3\": STA_IS['IS3'].values.tolist(),\n",
    "#                            \"y\": STA_counts[ind]})\n",
    "#         if distribution == \"Poisson\":\n",
    "#             mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.Poisson(), data=df).fit()\n",
    "#         elif distribution == \"Negative binomial\":\n",
    "#             mp = sm.formula.glm(\"y ~ x1 + x2 + x3\", family=sm.families.NegativeBinomial(), data=df).fit()\n",
    "#         else:\n",
    "#             print(\"Unknown distribution\")\n",
    "#             return\n",
    "#         learned_beta[:, ind] = np.array([mp.params.x1, mp.params.x2, mp.params.x3])\n",
    "\n",
    "\n",
    "    np.savez('{filename}_learnedbeta.npz'.format(filename=filename), beta=learned_beta)\n",
    "    \n",
    "    # leave only CR and OT classes for classification\n",
    "    OT_CR_counts = counts.loc[:, ~STA_patients].to_numpy(dtype=float)\n",
    "    OT_CR_IS = IS.loc[~STA_patients].values\n",
    "\n",
    "    # filter out IS from CR\n",
    "    OT_CR_counts[:, :n_CR] = OT_CR_counts[:, :n_CR] / np.exp(np.dot(OT_CR_IS[:n_CR], learned_beta).transpose())\n",
    "    OT_CR_counts = OT_CR_counts.transpose()\n",
    "    return OT_CR_counts, OT_CR_IS, learned_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def experiment_classification(n_transcripts, n_IS_effect, IS_effect, n_class_effect, class_effect_mean, STA_range, pool, filename):\n",
    "    n_repeats = 10\n",
    "    n_genSTA = 7000 # pocet nagenerovanych STA\n",
    "    n_genCR = 100\n",
    "    n_genOT = 100\n",
    "    _, _, _, gen_origin, gen_expected, gen_IS = rna_seq_generator(\n",
    "        n_transcripts=n_transcripts,\n",
    "        distribution=Distribution.NEGATIVE_BINOMIAL, #\"Negative binomial\",\n",
    "        n_STA=n_genSTA, n_CR=n_genCR, n_OT=n_genOT,\n",
    "        n_IS_effect=n_IS_effect, IS_effect=(IS_effect, IS_effect+0.01),  # IS effect\n",
    "        is_class_effect=n_class_effect > 0, n_class_effect=n_class_effect, class_effect=NormalDistributionParameters(class_effect_mean, 0.1)\n",
    "    )\n",
    "    mean_auc_results_origin, mean_auc_results_expected, mean_auc_results_filtered = \\\n",
    "        experiment_iteration(STA_range, n_repeats,\n",
    "                             gen_origin, gen_expected, gen_IS,\n",
    "                             n_genSTA, n_genCR, n_genOT, \"Negative binomial\", pool, filename) #\"Negative binomial\")\n",
    "    return mean_auc_results_origin, mean_auc_results_expected, mean_auc_results_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new IS_effect_n_transcripts:  2\n",
      "new IS_effect:  0.3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'experiment_iteration' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_p/6xmdmxy54p77x6qjslskgcbc0000gn/T/ipykernel_62899/3807808968.py\u001b[0m in \u001b[0;36mexperiment_classification\u001b[0;34m(n_transcripts, n_IS_effect, IS_effect, n_class_effect, class_effect_mean, STA_range, pool, filename)\u001b[0m\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     13\u001b[0m     \u001b[0mmean_auc_results_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_auc_results_expected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_auc_results_filtered\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         experiment_iteration(STA_range, n_repeats,\n\u001b[0m\u001b[1;32m     15\u001b[0m                              \u001b[0mgen_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_expected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_IS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                              n_genSTA, n_genCR, n_genOT, \"Negative binomial\", pool, filename) #\"Negative binomial\")\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiment_iteration' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "transcripts = [1000]#[100, 1000] #, 10000]\n",
    "class_effect_n_transcripts = [2]#[0, 2, 5, 10]\n",
    "class_effect = [0.2] #, 0.3, 0.4]  # mean of normal distribution\n",
    "\n",
    "IS_effect_n_transcripts = [2]#, 5, 10]\n",
    "IS_effect = [0.3]#, 0.5, 0.9]  # coefficients beta1..beta3\n",
    "\n",
    "# transcripts = [10000]\n",
    "# class_effect_n_transcripts = [0, 5, 10]\n",
    "# class_effect = [0.3, 0.4]  # mean of normal distribution\n",
    "\n",
    "# IS_effect_n_transcripts = [5, 10]\n",
    "# IS_effect = [0.5, 0.9]  # coefficients beta1..beta3\n",
    "with Pool() as pool:\n",
    "    for t in transcripts:\n",
    "        for n_IS in IS_effect_n_transcripts:\n",
    "            print('new IS_effect_n_transcripts: ', n_IS)\n",
    "            for i in IS_effect:\n",
    "                print('new IS_effect: ', i)\n",
    "                for n_class in class_effect_n_transcripts:\n",
    "                    if n_class == 0:\n",
    "                        c = 0.2\n",
    "                        filename = 'generateddata04_08/{t}_{n_IS}_{i}_{n_class}'.format(t=t, n_IS=n_IS, i=i, n_class=n_class)\n",
    "                        mean_o, mean_e, mean_f = experiment_classification(t, n_IS, i, n_class, c, STA_range, pool, filename)\n",
    "                        saved_origin[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_origin[t][n_IS][i][n_class][c]['auc'] = mean_o\n",
    "\n",
    "                        saved_expected[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_expected[t][n_IS][i][n_class][c]['auc'] = mean_e\n",
    "\n",
    "                        saved_filtered[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                        saved_filtered[t][n_IS][i][n_class][c]['auc'] = mean_f\n",
    "                    else:\n",
    "                        for c in class_effect:\n",
    "                            STA_range = [10, 20, 50, 100, 200, 500, 1000, 2000, 5000]\n",
    "                            \n",
    "                            filename = 'generateddata04_08/{t}_{n_IS}_{i}_{n_class}_{c}'.format(t=t, n_IS=n_IS, i=i, n_class=n_class, c=c)\n",
    "\n",
    "                            mean_o, mean_e, mean_f = experiment_classification(t, n_IS, i, n_class, c, STA_range, pool, filename)\n",
    "                            saved_origin[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                            saved_origin[t][n_IS][i][n_class][c]['auc'] = mean_o\n",
    "\n",
    "                            saved_expected[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                            saved_expected[t][n_IS][i][n_class][c]['auc'] = mean_e\n",
    "\n",
    "                            saved_filtered[t][n_IS][i][n_class][c]['STA_range'] = STA_range\n",
    "                            saved_filtered[t][n_IS][i][n_class][c]['auc'] = mean_f\n",
    "\n",
    "                np.savez('auc_results_origin.npz', auc_data=saved_origin)\n",
    "                np.savez('auc_results_expected.npz', auc_data=saved_expected)\n",
    "                np.savez('auc_results_filtered.npz', auc_data=saved_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save data\n",
    "np.savez('auc_results_origin5-poisson.npz', auc_data=saved_origin)\n",
    "np.savez('auc_results_expected5-poisson.npz', auc_data=saved_expected)\n",
    "np.savez('auc_results_filtered5-poisson.npz', auc_data=saved_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 9]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        print(p.map(f, [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
